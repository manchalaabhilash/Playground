{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal RAG Demo\n",
    "\n",
    "This notebook demonstrates how to use the Multimodal RAG system to answer questions about both text documents and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "from src.multimodal_rag import MultimodalRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize the Multimodal RAG System\n",
    "\n",
    "First, we need to initialize the RAG system with our documents and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List your documents and images\n",
    "document_paths = [\n",
    "    \"../data/documents/sample_document.pdf\"  # Replace with your actual document path\n",
    "]\n",
    "\n",
    "image_paths = [\n",
    "    \"../data/images/sample_image.jpg\"  # Replace with your actual image path\n",
    "]\n",
    "\n",
    "# Initialize Multimodal RAG system\n",
    "rag = MultimodalRAG(document_paths=document_paths, image_paths=image_paths)\n",
    "\n",
    "# Process documents and images\n",
    "num_text_chunks = rag.process_documents()\n",
    "num_images = rag.process_images()\n",
    "\n",
    "print(f\"Processed {num_text_chunks} text chunks from {len(document_paths)} documents\")\n",
    "print(f\"Processed {num_images} images\")\n",
    "\n",
    "# Initialize vector database\n",
    "rag.initialize_vector_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ask Questions with Multimodal RAG\n",
    "\n",
    "Now we can ask questions about our documents and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question with RAG\n",
    "question = \"What is shown in the image and how does it relate to the document?\"\n",
    "answer = rag.answer_question(question, use_rag=True)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare with Direct LLM (No RAG)\n",
    "\n",
    "Let's compare the answers with and without RAG to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the same question without RAG\n",
    "answer_no_rag = rag.answer_question(question, use_rag=False)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer (No RAG): {answer_no_rag}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "py